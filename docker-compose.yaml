networks:
  network:
    driver: bridge

volumes:
  prometheus:
  healthcheck-build:

services:
  ####################################################
  # Data Storage                                     #
  ####################################################
  minio:
    container_name: minio
    image: minio/minio:RELEASE.2025-06-13T11-33-47Z
    restart: unless-stopped
    command: ["server", "/data", "--console-address", ":9001"]
    networks:
      - network
    environment:
      MINIO_ROOT_USER: ${ADMIN_USER}
      MINIO_ROOT_PASSWORD: ${ADMIN_PASS}
      MINIO_CONSOLE_ADDRESS: :9001
      MINIO_BROWSER_REDIRECT_URL: ${HOST_URI}/storage
      MINIO_PROMETHEUS_AUTH_TYPE: public
    ulimits:
      nofile:
        soft: 4096
        hard: 65535
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 15s
      timeout: 10s
      retries: 5

  postgres:
    container_name: postgres
    image: postgres:17.5
    restart: unless-stopped
    ports:
      - 5432:5432
    networks:
      - network
    volumes:
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    environment:
      POSTGRES_PASSWORD: ${DB_PASS}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 15s
      timeout: 10s
      retries: 5

  redis:
    container_name: redis
    image: redis:8.0.2
    restart: unless-stopped
    command: ["redis-server", "--maxmemory", "2gb"]
    networks:
      - network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 15s
      timeout: 10s
      retries: 5

  ####################################################
  # Authentification                                 #
  ####################################################

  keycloak:
    container_name: keycloak
    build:
      context: ./keycloak
      args:
        KC_URI: ${HOST_URI}/auth
        GF_URI: ${HOST_URI}/dashboard
        GF_CLIENT_SECRET: ${GF_CLIENT_SECRET}
    restart: unless-stopped
    command:
      ["start", "--optimized", "--import-realm", "--hostname=${HOST_URI}/auth"]
    networks:
      - network
    environment:
      KC_BOOTSTRAP_ADMIN_USERNAME: ${ADMIN_USER}
      KC_BOOTSTRAP_ADMIN_PASSWORD: ${ADMIN_PASS}
      KC_HOSTNAME_STRICT: false
      KC_HTTP_ENABLED: true
      KC_DB_URL_HOST: postgres
      KC_DB_URL_PORT: 5432
      KC_DB_SCHEMA: keycloak
      KC_DB_URL_DATABASE: postgres
      KC_DB: postgres
      KC_DB_USERNAME: postgres
      KC_DB_PASSWORD: ${DB_PASS}
      KC_HTTP_PORT: 8080
    healthcheck:
      test:
        [
          "CMD-SHELL",
          '[ -f /tmp/HealthCheck.java ] || echo "public class HealthCheck { public static void main(String[] args) throws java.lang.Throwable { System.exit(java.net.HttpURLConnection.HTTP_OK == ((java.net.HttpURLConnection)new java.net.URL(args[0]).openConnection()).getResponseCode() ? 0 : 1); } }" > /tmp/HealthCheck.java && java /tmp/HealthCheck.java http://localhost:9000/health/live',
        ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 15s
    depends_on:
      postgres:
        condition: "service_healthy"

  ####################################################
  # Monitoring                                       #
  ####################################################

  prometheus:
    container_name: prometheus
    image: prom/prometheus:v3.4.1
    restart: unless-stopped
    user: 0:0 # haven't gotten it to work without yet (needed for the shared Prometheus volume)
    ports:
      - 9090:9090
    command:
      [
        "--config.file=/etc/prometheus/config.yaml",
        "--storage.tsdb.path=/data",
        "--storage.tsdb.retention.time=1d",
        "--storage.tsdb.min-block-duration=5m",
        "--storage.tsdb.max-block-duration=5m",
        "--web.enable-lifecycle",
        "--web.enable-admin-api",
        "--web.console.libraries=/etc/prometheus/console_libraries",
        "--web.console.templates=/etc/prometheus/consoles",
      ]
    networks:
      - network
    volumes:
      - ./prometheus/config.yaml:/etc/prometheus/config.yaml:ro
      - prometheus:/data:rw
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 15s
      timeout: 10s
      retries: 5

  thanos-sidecar:
    container_name: thanos-sidecar
    image: quay.io/thanos/thanos:v0.39.1
    restart: unless-stopped
    user: 0:0 # haven't gotten it to work without yet (needed for the shared Prometheus volume)
    networks:
      - network
    volumes:
      - ./prometheus/config.yaml:/etc/config/config.yaml:ro
      - prometheus:/data:rw
    command:
      - "sidecar"
      - "--tsdb.path=/data"
      - "--prometheus.url=http://prometheus:9090"
      - "--reloader.config-file=/etc/config/config.yaml"
      - |
        --objstore.config=type: S3
        config:
          bucket: prometheus
          access_key: ${ADMIN_USER}
          secret_key: ${ADMIN_PASS}
          endpoint: minio:9000
          insecure: true
    healthcheck:
      test:
        ["CMD", "wget", "--spider", "-q", "http://localhost:10902/-/healthy"]
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      prometheus:
        condition: "service_healthy"
      minio:
        condition: "service_healthy"

  thanos-store:
    container_name: thanos-store
    image: quay.io/thanos/thanos:v0.39.1
    restart: unless-stopped
    user: 0:0 # haven't gotten it to work without yet (needed for the shared Prometheus volume)
    networks:
      - network
    command:
      - "store"
      - "--index-cache-size=250MB"
      - "--chunk-pool-size=2GB"
      - |
        --objstore.config=type: S3
        config:
          bucket: prometheus
          access_key: ${ADMIN_USER}
          secret_key: ${ADMIN_PASS}
          endpoint: minio:9000
          insecure: true
    volumes:
      - prometheus:/data:rw
    healthcheck:
      test:
        ["CMD", "wget", "--spider", "-q", "http://localhost:10902/-/healthy"]
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      prometheus:
        condition: "service_healthy"
      minio:
        condition: "service_healthy"

  thanos-query:
    container_name: thanos-query
    image: quay.io/thanos/thanos:v0.39.1
    restart: unless-stopped
    networks:
      - network
    command:
      - "query"
      - "--http-address=0.0.0.0:9090"
      - "--grpc-address=0.0.0.0:9091"
      - "--query.timeout=2m"
      - "--endpoint=thanos-store:10901"
      - "--endpoint=thanos-sidecar:10901"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      thanos-sidecar:
        condition: "service_healthy"
      thanos-store:
        condition: "service_healthy"

  tempo:
    container_name: tempo
    build:
      context: ./tempo
      args:
        ACCESS_KEY: ${ADMIN_USER}
        SECRET_KEY: ${ADMIN_PASS}
    restart: unless-stopped
    command: ["-config.file=/etc/config.yaml"]
    networks:
      - network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3200/ready"]
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      minio:
        condition: "service_healthy"
      redis:
        condition: "service_healthy"
      prometheus:
        condition: "service_healthy"

  grafana:
    container_name: grafana
    build:
      context: ./grafana
      args:
        GF_URI: ${HOST_URI}/dashboard
        KC_URI: ${HOST_URI}/auth
        GF_CLIENT_SECRET: ${GF_CLIENT_SECRET}
        DB_PASS: ${DB_PASS}
    restart: unless-stopped
    networks:
      - network
    volumes:
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    environment:
      GF_SECURITY_ADMIN_USER: ${ADMIN_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${ADMIN_PASS}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      keycloak:
        condition: "service_healthy"

  ####################################################
  # Traffic Entrypoint                               #
  ####################################################

  cloudflare-tunnel:
    container_name: cloudflare-tunnel
    image: cloudflare/cloudflared:1710-3f6b1f24d036
    restart: unless-stopped
    command: tunnel --metrics 0.0.0.0:6000 run --token ${TUNNEL_TOKEN}
    networks:
      - network
    volumes:
      - healthcheck-build:/usr/bin/healthcheck:ro
    healthcheck:
      test:
        [
          "CMD",
          "/usr/bin/healthcheck/healthcheck",
          "http://localhost:6000/ready",
        ]
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      nginx:
        condition: "service_healthy"

  nginx:
    container_name: nginx
    build:
      context: ./nginx
    restart: unless-stopped
    networks:
      - network
    # the port config can be removed in production
    ports:
      - 5000:80
    healthcheck:
      test: service nginx status || exit 1
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      keycloak:
        condition: "service_healthy"
      grafana:
        condition: "service_healthy"

  ####################################################
  # Metric Exporter                                  #
  ####################################################

  cadvisor:
    container_name: cadvisor
    image: gcr.io/cadvisor/cadvisor:v0.52.0
    restart: unless-stopped
    privileged: true
    networks:
      - network
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/"]
      interval: 15s
      timeout: 10s
      retries: 5

  node-exporter:
    image: prom/node-exporter:v1.9.1
    container_name: node-exporter
    restart: unless-stopped
    command:
      - "--path.procfs=/host/proc"
      - "--path.rootfs=/rootfs"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
    networks:
      - network
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9100/"]
      interval: 15s
      timeout: 10s
      retries: 5

  nginx-exporter:
    container_name: nginx-exporter
    image: nginx/nginx-prometheus-exporter:1.4.2
    restart: unless-stopped
    command: ["--nginx.scrape-uri=http://nginx:8080/stub_status"]
    networks:
      - network
    volumes:
      - healthcheck-build:/usr/bin/healthcheck:ro
    healthcheck:
      test:
        ["CMD", "/usr/bin/healthcheck/healthcheck", "http://localhost:9113/"]
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      nginx:
        condition: "service_healthy"

  postgres-exporter:
    container_name: postgres-exporter
    image: prometheuscommunity/postgres-exporter:v0.17.1
    restart: unless-stopped
    networks:
      - network
    environment:
      DATA_SOURCE_URI: "postgres:5432/postgres?sslmode=disable"
      DATA_SOURCE_USER: postgres
      DATA_SOURCE_PASS: ${DB_PASS}
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9187/"]
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      postgres:
        condition: "service_healthy"

  redis-exporter:
    container_name: redis-exporter
    image: bitnami/redis-exporter:1.74.0
    restart: unless-stopped
    networks:
      - network
    volumes:
      - healthcheck-build:/usr/bin/healthcheck:ro
    environment:
      REDIS_ADDR: redis://redis:6379
    healthcheck:
      test:
        ["CMD", "/usr/bin/healthcheck/healthcheck", "http://localhost:9121/"]
      interval: 15s
      timeout: 10s
      retries: 5
    depends_on:
      redis:
        condition: "service_healthy"

  ####################################################
  # Single Run                                       #
  ####################################################

  # https://stackoverflow.com/questions/66412289/minio-add-a-public-bucket-with-docker-compose
  create-buckets:
    container_name: create-buckets
    image: minio/mc:RELEASE.2025-04-16T18-13-26Z
    networks:
      - network
    depends_on:
      minio:
        condition: "service_healthy"
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set myminio http://minio:9000 ${ADMIN_USER} ${ADMIN_PASS};
      /usr/bin/mc mb myminio/prometheus;
      /usr/bin/mc mb myminio/tempo;
      exit 0;
      "

  healthcheck-build:
    container_name: healthcheck-build
    build:
      context: ./healthcheck
    volumes:
      - healthcheck-build:/healthcheck
